{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["cj8gjqE1BTQc"],"authorship_tag":"ABX9TyPcRedt3Qxl5tzRJuNhdTAe"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"TeQVzXu3dVes"},"outputs":[],"source":["!pip install swig\n","!pip install box2d-py\n","!pip install gymnasium[box2d]\n","!pip install tf_agents"]},{"cell_type":"code","source":["!pip install tf_agents\n","!pip install swig\n","!pip install box2d-py\n","!pip install gym[box2d]\n","!pip install gym[atari]\n","!pip install autorom[accept-rom-license]"],"metadata":{"id":"pbZfacADSeuw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import gymnasium as gym"],"metadata":{"id":"gCOBLtH175xx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import gym"],"metadata":{"id":"BASHmFOL9dlw","executionInfo":{"status":"ok","timestamp":1719814975821,"user_tz":-120,"elapsed":377,"user":{"displayName":"Tomas David","userId":"17081504748808486304"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["import os\n","import time\n","import numpy as np\n","import tensorflow as tf\n","import tensorflow.keras as keras\n","from tensorflow.keras import layers"],"metadata":{"id":"rw7J1EXw5iuV","executionInfo":{"status":"ok","timestamp":1719814827862,"user_tz":-120,"elapsed":7448,"user":{"displayName":"Tomas David","userId":"17081504748808486304"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["from tf_agents.environments.atari_preprocessing import AtariPreprocessing\n","from tf_agents.environments.atari_wrappers import FrameStack4\n","from tf_agents.environments import suite_atari\n","from tf_agents.environments.tf_py_environment import TFPyEnvironment\n","from tf_agents.networks.q_network import QNetwork\n","from tf_agents.agents.dqn.dqn_agent import DqnAgent\n","from tf_agents.replay_buffers import tf_uniform_replay_buffer\n","from tf_agents.metrics import tf_metrics\n","from tf_agents.eval.metric_utils import log_metrics\n","from tf_agents.drivers.dynamic_step_driver import DynamicStepDriver\n","from tf_agents.policies.random_tf_policy import RandomTFPolicy\n","from tf_agents.trajectories.trajectory import to_transition\n","from tf_agents.utils.common import function"],"metadata":{"id":"zZ9CqPfE60B1","executionInfo":{"status":"ok","timestamp":1719814832689,"user_tz":-120,"elapsed":4829,"user":{"displayName":"Tomas David","userId":"17081504748808486304"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount(\"/content/gdrive\")\n","drive_path = \"gdrive/MyDrive/MachineLearning/HandsOnMachineLearning/chapter18\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PgJRkf81BKSk","executionInfo":{"status":"ok","timestamp":1719814884384,"user_tz":-120,"elapsed":19111,"user":{"displayName":"Tomas David","userId":"17081504748808486304"}},"outputId":"dd249512-43e4-4f0d-d175-98f5171ba0b7"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}]},{"cell_type":"code","source":["os.makedirs(f\"{drive_path}/models\", exist_ok=True)"],"metadata":{"id":"c2bqKaz7BOfm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 8."],"metadata":{"id":"cj8gjqE1BTQc"}},{"cell_type":"code","source":["env = gym.make(\"LunarLander-v2\")\n","env.max_episode_steps = 500"],"metadata":{"id":"LG9BO5FQ5nCk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = keras.models.Sequential([\n","    layers.Dense(16, activation=\"relu\", input_shape=[8]),\n","    layers.Dense(16, activation=\"relu\"),\n","    layers.Dense(16, activation=\"relu\"),\n","    layers.Dense(4, activation=\"softmax\")\n","])"],"metadata":{"id":"T35WEMqdOKqy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["onehot_encodings = tf.one_hot([0, 1, 2, 3], 4)"],"metadata":{"id":"LjK3CgKxT6jq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def play_one_step(env, obs, model, loss_fn):\n","    with tf.GradientTape() as tape:\n","        probabilities = model(obs[np.newaxis])\n","        probabilities = tf.cast(probabilities[-1], tf.float64)\n","        probabilities /= np.sum(probabilities)\n","        action = np.random.choice(4, p=probabilities)\n","        y_target = onehot_encodings[action]\n","        loss = tf.reduce_mean(loss_fn(y_target, probabilities))\n","    grads = tape.gradient(loss, model.trainable_variables)\n","    obs, reward, done, truncated, info = env.step(action)\n","    return obs, reward, done, grads"],"metadata":{"id":"wKoEh7NJIluY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def play_multiple_episodes(env, n_episodes, n_max_steps, model, loss_fn):\n","    all_rewards = []\n","    all_grads = []\n","    for episode in range(n_episodes):\n","        current_rewards = []\n","        current_grads = []\n","        obs = env.reset()[0]\n","        for step in range(n_max_steps):\n","            obs, reward, done, grads = play_one_step(env, obs, model, loss_fn)\n","            current_rewards.append(reward)\n","            current_grads.append(grads)\n","            if done:\n","                break\n","        all_rewards.append(current_rewards)\n","        all_grads.append(current_grads)\n","    return all_rewards, all_grads"],"metadata":{"id":"BqorIKWDMzzr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def discount_rewards(rewards, discount_factor):\n","    discounted = np.array(rewards)\n","    for step in range(len(rewards) - 2, -1, -1):\n","        discounted[step] += discounted[step + 1] * discount_factor\n","    return discounted\n","\n","\n","def discount_and_normalize_rewards(all_rewards, discount_factor):\n","    all_discounted_rewards = [discount_rewards(rewards, discount_factor)\n","                              for rewards in all_rewards]\n","    flat_rewards = np.concatenate(all_discounted_rewards)\n","    reward_mean = flat_rewards.mean()\n","    reward_std = flat_rewards.std()\n","    return [(discounted_rewards - reward_mean) / reward_std\n","            for discounted_rewards in all_discounted_rewards]"],"metadata":{"id":"6kS6D3swNM3Z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["checkpoint_dir = time.strftime(f\"{drive_path}/models/lunarlander_%Y_%m_%d-%H_%M_%S\")\n","os.makedirs(checkpoint_dir, exist_ok=True)\n","checkpoint_prefix = os.path.join(checkpoint_dir, \"lunarlander\")\n","checkpoint = tf.train.Checkpoint(model)"],"metadata":{"id":"KAv5AFfLXZyr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["checkpoint.restore(f\"{drive_path}/models/lunarlander_2024_06_28-12_08_31\")"],"metadata":{"id":"q0R20CRhxdmA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["n_iterations = 150\n","n_episodes_per_update = 10\n","n_max_steps = 200\n","discount_factor = 0.99\n","\n","optimizer = keras.optimizers.Adam(learning_rate=0.01)\n","loss_fn = keras.losses.binary_crossentropy\n","\n","for iteration in range(n_iterations):\n","    start = time.time()\n","\n","    all_rewards, all_grads = play_multiple_episodes(env, n_episodes_per_update,\n","                                                    n_max_steps, model, loss_fn)\n","    all_final_rewards = discount_and_normalize_rewards(all_rewards, discount_factor)\n","    all_mean_grads = []\n","    for var_index in range(len(model.trainable_variables)):\n","        mean_grads = tf.reduce_mean(\n","            [final_reward * all_grads[episode_index][step][var_index]\n","             for episode_index, final_rewards in enumerate(all_final_rewards)\n","                 for step, final_reward in enumerate(final_rewards)], axis=0)\n","        all_mean_grads.append(mean_grads)\n","    optimizer.apply_gradients(zip(all_mean_grads, model.trainable_variables))\n","\n","    times_won = 0\n","    for rewards in all_rewards:\n","        times_won += rewards.count(200)\n","\n","    # Save the model every 20 epochs\n","    if (iteration + 1) % 20 == 0:\n","        checkpoint.save(file_prefix=checkpoint_prefix)\n","\n","    print('Time for iteration {} is {} sec, times won: {}'.format(\n","        iteration+1, time.time()-start, times_won\n","    ))"],"metadata":{"id":"KLZEcGiXNmNu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 9."],"metadata":{"id":"utxAnvk1KLB1"}},{"cell_type":"code","source":["max_episode_steps = 50000\n","\n","env = suite_atari.load(\n","    \"SpaceInvaders-v4\",\n","    max_episode_steps=max_episode_steps,\n","    gym_env_wrappers=[AtariPreprocessing, FrameStack4]\n",")\n","tf_env = TFPyEnvironment(env)"],"metadata":{"id":"xjPGAvJ-KNiq","executionInfo":{"status":"ok","timestamp":1719814853027,"user_tz":-120,"elapsed":464,"user":{"displayName":"Tomas David","userId":"17081504748808486304"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["preprocessing_layer = layers.Lambda(\n","    lambda obs: tf.cast(obs, np.float32) / 255.\n",")\n","conv_layer_params = [\n","    (32, (8, 8), 4),\n","    (64, (4, 4), 2),\n","    (64, (3, 3), 1)\n","]\n","fc_layer_params = [512]\n","q_net = QNetwork(\n","    tf_env.observation_spec(),\n","    tf_env.action_spec(),\n","    preprocessing_layers=preprocessing_layer,\n","    conv_layer_params=conv_layer_params,\n","    fc_layer_params=fc_layer_params\n",")"],"metadata":{"id":"Yfhpg4U51jjd","executionInfo":{"status":"ok","timestamp":1719814858180,"user_tz":-120,"elapsed":825,"user":{"displayName":"Tomas David","userId":"17081504748808486304"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["train_step = tf.Variable(0)\n","update_period = 4\n","optimizer = keras.optimizers.RMSprop(lr=2.5e-4, rho=0.95, momentum=0.0,\n","                                     epsilon=0.00001, centered=True)\n","epsilon_fn = keras.optimizers.schedules.PolynomialDecay(\n","    initial_learning_rate=1.0,  # initial ε\n","    decay_steps= 1.0 // 0.00001,\n","    end_learning_rate=0.01  # final ε\n",")\n","agent = DqnAgent(tf_env.time_step_spec(),\n","    tf_env.action_spec(),\n","    q_network=q_net,\n","    optimizer=optimizer,\n","    target_update_period=2000,\n","    td_errors_loss_fn=keras.losses.Huber(reduction=\"none\"),\n","    gamma=0.9,  # discount factor\n","    train_step_counter=train_step,\n","    epsilon_greedy=lambda: epsilon_fn(train_step)\n",")\n","agent.initialize()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bSfOPL1O6o0l","executionInfo":{"status":"ok","timestamp":1719814863600,"user_tz":-120,"elapsed":1367,"user":{"displayName":"Tomas David","userId":"17081504748808486304"}},"outputId":"224d0549-ac5c-4f1e-ca5c-1b0e67cea637"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n"]}]},{"cell_type":"code","source":["replay_buffer = tf_uniform_replay_buffer.TFUniformReplayBuffer(\n","    data_spec=agent.collect_data_spec,\n","    batch_size=tf_env.batch_size,\n","    #max_length=1000000\n","    max_length=100000\n",")"],"metadata":{"id":"wO2G-YdI8UOT","executionInfo":{"status":"ok","timestamp":1719814886744,"user_tz":-120,"elapsed":2363,"user":{"displayName":"Tomas David","userId":"17081504748808486304"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["replay_buffer_observer = replay_buffer.add_batch"],"metadata":{"id":"EK3vVgss9imL","executionInfo":{"status":"ok","timestamp":1719814890916,"user_tz":-120,"elapsed":349,"user":{"displayName":"Tomas David","userId":"17081504748808486304"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["train_metrics = [\n","    tf_metrics.NumberOfEpisodes(),\n","    tf_metrics.EnvironmentSteps(),\n","    tf_metrics.AverageReturnMetric(),\n","    tf_metrics.AverageEpisodeLengthMetric(),\n","]"],"metadata":{"id":"S8Gamtb29jWA","executionInfo":{"status":"ok","timestamp":1719814892170,"user_tz":-120,"elapsed":4,"user":{"displayName":"Tomas David","userId":"17081504748808486304"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["collect_driver = DynamicStepDriver(\n","    tf_env,\n","    agent.collect_policy,\n","    observers=[replay_buffer_observer] + train_metrics,\n","    num_steps=update_period  # collect 4 steps for each training iteration\n",")"],"metadata":{"id":"ieEq06aK9z25","executionInfo":{"status":"ok","timestamp":1719814893937,"user_tz":-120,"elapsed":4,"user":{"displayName":"Tomas David","userId":"17081504748808486304"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["class ShowProgress():\n","    def __init__(self, total):\n","        self.counter = 0\n","        self.total = total\n","\n","    def __call__(self, trajectory):\n","        if not trajectory.is_boundary():\n","            self.counter += 1\n","        if self.counter % 100 == 0:\n","            print(\"\\r{}/{}\".format(self.counter, self.total), end=\"\")\n"],"metadata":{"id":"DqltFJzR-zex","executionInfo":{"status":"ok","timestamp":1719814894996,"user_tz":-120,"elapsed":2,"user":{"displayName":"Tomas David","userId":"17081504748808486304"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["initial_collect_policy = RandomTFPolicy(tf_env.time_step_spec(),\n","                                        tf_env.action_spec())\n","init_driver = DynamicStepDriver(\n","    tf_env,\n","    initial_collect_policy,\n","    observers=[replay_buffer.add_batch, ShowProgress(20000)],\n","    num_steps=20000\n",")\n","final_time_step, final_policy_state = init_driver.run()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HOyIuXKu-j1r","executionInfo":{"status":"ok","timestamp":1719815211110,"user_tz":-120,"elapsed":225026,"user":{"displayName":"Tomas David","userId":"17081504748808486304"}},"outputId":"29eaf8b3-5939-4ce4-9088-7ae0e49f525c"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["20000/20000"]}]},{"cell_type":"code","source":["dataset = replay_buffer.as_dataset(\n","    sample_batch_size=64,\n","    num_steps=2,\n","    num_parallel_calls=3\n",")\n","dataset = dataset.prefetch(3)"],"metadata":{"id":"_nqVexbYBA5c","executionInfo":{"status":"ok","timestamp":1719815212339,"user_tz":-120,"elapsed":1251,"user":{"displayName":"Tomas David","userId":"17081504748808486304"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"4b57d810-c764-4da4-b709-24fbc1ef416e"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py:377: ReplayBuffer.get_next (from tf_agents.replay_buffers.replay_buffer) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `as_dataset(..., single_deterministic_pass=False) instead.\n"]}]},{"cell_type":"code","source":["collect_driver.run = function(collect_driver.run)\n","agent.train = function(agent.train)"],"metadata":{"id":"ki0DhSdYJPjZ","executionInfo":{"status":"ok","timestamp":1719815212340,"user_tz":-120,"elapsed":8,"user":{"displayName":"Tomas David","userId":"17081504748808486304"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["checkpoint_dir = time.strftime(f\"{drive_path}/models/spaceinvaders_%Y_%m_%d-%H_%M_%S\")\n","os.makedirs(checkpoint_dir, exist_ok=True)\n","checkpoint_prefix = os.path.join(checkpoint_dir, \"spaceinvaders\")\n","checkpoint = tf.train.Checkpoint(agent)"],"metadata":{"id":"YS0W9Yv0R-RY","executionInfo":{"status":"ok","timestamp":1719815440154,"user_tz":-120,"elapsed":377,"user":{"displayName":"Tomas David","userId":"17081504748808486304"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["def train_agent(n_iterations):\n","    time_step = None\n","    policy_state = agent.collect_policy.get_initial_state(tf_env.batch_size)\n","    iterator = iter(dataset)\n","    for iteration in range(n_iterations):\n","        time_step, policy_state = collect_driver.run(time_step, policy_state)\n","        trajectories, buffer_info = next(iterator)\n","        train_loss = agent.train(trajectories)\n","        print(\"\\r{} loss:{:.5f}\".format(iteration, train_loss.loss.numpy()), end=\"\")\n","        if iteration % 100 == 0:\n","            log_metrics(train_metrics)\n","            checkpoint.save(file_prefix=checkpoint_prefix)"],"metadata":{"id":"7m8QDSV4JcFo","executionInfo":{"status":"ok","timestamp":1719815442900,"user_tz":-120,"elapsed":362,"user":{"displayName":"Tomas David","userId":"17081504748808486304"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["train_agent(100000)"],"metadata":{"id":"kzJVlXX5KOKU","executionInfo":{"status":"ok","timestamp":1719815449966,"user_tz":-120,"elapsed":5064,"user":{"displayName":"Tomas David","userId":"17081504748808486304"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"bd7d4a0b-f030-4a48-d6b5-480c932888c7"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1260: calling foldr_v2 (from tensorflow.python.ops.functional_ops) with back_prop=False is deprecated and will be removed in a future version.\n","Instructions for updating:\n","back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n","Instead of:\n","results = tf.foldr(fn, elems, back_prop=False)\n","Use:\n","results = tf.nest.map_structure(tf.stop_gradient, tf.foldr(fn, elems))\n"]},{"output_type":"stream","name":"stdout","text":["\r0 loss:0.91701"]}]}]}