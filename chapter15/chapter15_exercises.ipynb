{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNn6lmG+Y0J9QkV17kEvZtB"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import tensorflow.keras as keras\n","from tensorflow.keras import layers\n","import tensorflow as tf\n","import tensorflow_datasets as tfds\n","import time\n","import os\n","import re\n","import numpy as np\n","from pathlib import Path"],"metadata":{"id":"gZAwnLZaIOAu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount(\"/content/gdrive\")\n","drive_path = \"gdrive/MyDrive/MachineLearning/HandsOnMachineLearning/chapter15\""],"metadata":{"id":"u9AIwFCpLRVG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1719067531599,"user_tz":-120,"elapsed":21320,"user":{"displayName":"Tomas David","userId":"17081504748808486304"}},"outputId":"7bc3e3ab-c479-4418-e433-e9640980c893"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}]},{"cell_type":"markdown","source":["# 9."],"metadata":{"id":"Gf-S2x74G9aT"}},{"cell_type":"code","source":["DOWNLOAD_ROOT = \"http://download.tensorflow.org/data/\"\n","FILENAME = \"quickdraw_tutorial_dataset_v1.tar.gz\"\n","filepath = keras.utils.get_file(FILENAME, DOWNLOAD_ROOT + FILENAME, extract=True)\n","path = Path(filepath).parent"],"metadata":{"id":"me1xHsHpRoLd","executionInfo":{"status":"ok","timestamp":1719061936611,"user_tz":-120,"elapsed":76610,"user":{"displayName":"Tomas David","userId":"17081504748808486304"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"9f04149a-9723-45ff-bf7c-0b3e8f4cab00"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from http://download.tensorflow.org/data/quickdraw_tutorial_dataset_v1.tar.gz\n","1065301781/1065301781 [==============================] - 49s 0us/step\n"]}]},{"cell_type":"code","source":["def get_filepaths(split, path):\n","    regex = re.compile(split + \".tfrecord-\\d{5}-of-\\d{5}\")\n","    filepaths = []\n","    for root, dirs, files in os.walk(path):\n","        for file in files:\n","            if re.match(regex, file):\n","                filepaths.append(str(path / file))\n","    return filepaths"],"metadata":{"id":"Vd6Vrz0t0qSi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_filepaths = get_filepaths(\"training\", path)\n","eval_filepaths = get_filepaths(\"eval\", path)\n","print(train_filepaths)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lm7MJuUL5NIT","executionInfo":{"status":"ok","timestamp":1719061936612,"user_tz":-120,"elapsed":30,"user":{"displayName":"Tomas David","userId":"17081504748808486304"}},"outputId":"63e9bc8d-e9b9-46d5-fc63-ac8bce1128b1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['/root/.keras/datasets/training.tfrecord-00004-of-00010', '/root/.keras/datasets/training.tfrecord-00001-of-00010', '/root/.keras/datasets/training.tfrecord-00008-of-00010', '/root/.keras/datasets/training.tfrecord-00009-of-00010', '/root/.keras/datasets/training.tfrecord-00003-of-00010', '/root/.keras/datasets/training.tfrecord-00000-of-00010', '/root/.keras/datasets/training.tfrecord-00007-of-00010', '/root/.keras/datasets/training.tfrecord-00006-of-00010', '/root/.keras/datasets/training.tfrecord-00005-of-00010', '/root/.keras/datasets/training.tfrecord-00002-of-00010']\n"]}]},{"cell_type":"code","source":["def list_record_features(tfrecord_path):\n","    for rec in tf.data.TFRecordDataset(tfrecord_path).skip(100).take(10):\n","        example_bytes = rec.numpy()\n","        example = tf.train.Example()\n","        example.ParseFromString(example_bytes)\n","        for key, value in example.features.feature.items():\n","            kind = value.WhichOneof(\"kind\")\n","            size = len(getattr(value, kind).value)\n","            print(f\"key:  {key}\", f\"kind: {kind}\", f\"size: {size}\",\n","                  sep=\"\\n\", end=\"\\n\\n\")\n","\n","\n","list_record_features(train_filepaths[3])"],"metadata":{"id":"gw85wWta7_Lu","colab":{"base_uri":"https://localhost:8080/","height":339},"executionInfo":{"status":"error","timestamp":1719067739436,"user_tz":-120,"elapsed":301,"user":{"displayName":"Tomas David","userId":"17081504748808486304"}},"outputId":"ad938e26-65bc-487e-fd86-3ce5c1142f75"},"execution_count":null,"outputs":[{"output_type":"error","ename":"DataLossError","evalue":"{{function_node __wrapped__IteratorGetNext_output_types_1_device_/job:localhost/replica:0/task:0/device:CPU:0}} corrupted record at 0 (Is this even a TFRecord file?) [Op:IteratorGetNext] name: ","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mDataLossError\u001b[0m                             Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-a4eba4309e99>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mlist_record_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_filepaths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-10-a4eba4309e99>\u001b[0m in \u001b[0;36mlist_record_features\u001b[0;34m(tfrecord_path)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mlist_record_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtfrecord_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mrec\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFRecordDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtfrecord_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mskip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m         \u001b[0mexample_bytes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mexample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mexample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParseFromString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    808\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 810\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    811\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    771\u001b[0m     \u001b[0;31m# to communicate that there is no more data to iterate over.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    772\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecution_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSYNC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 773\u001b[0;31m       ret = gen_dataset_ops.iterator_get_next(\n\u001b[0m\u001b[1;32m    774\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    775\u001b[0m           \u001b[0moutput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36miterator_get_next\u001b[0;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m   3027\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3028\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3029\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3030\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3031\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   5881\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mNoReturn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5882\u001b[0m   \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5883\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5884\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5885\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mDataLossError\u001b[0m: {{function_node __wrapped__IteratorGetNext_output_types_1_device_/job:localhost/replica:0/task:0/device:CPU:0}} corrupted record at 0 (Is this even a TFRecord file?) [Op:IteratorGetNext] name: "]}]},{"cell_type":"code","source":["feature_description = {\n","    \"class_index\": tf.io.FixedLenFeature([], tf.int64),\n","    \"shape\": tf.io.FixedLenFeature([2], tf.int64),\n","    \"ink\": tf.io.VarLenFeature(tf.float32)\n","}\n","MAX_LENGTH = 100\n","\n","\n","def _parse_function(proto):\n","    example = tf.io.parse_single_example(proto, feature_description)\n","    class_index = example[\"class_index\"]\n","    ink = example[\"ink\"]\n","    ink = tf.sparse.to_dense(ink)\n","    ink = tf.reshape(ink, (-1, 3))\n","    return ink[:MAX_LENGTH], class_index\n","\n","\n","def image_generator(tfrecord_filepaths, max_length=100):\n","    raw_dataset = tf.data.TFRecordDataset(tfrecord_filepaths)\n","    dataset = raw_dataset.map(_parse_function, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n","\n","    for batch in dataset.padded_batch(batch_size, padded_shapes=([100, 3], [])).prefetch(1):\n","        yield batch\n","\n","\n","batch_size = 32\n","output_signature = (\n","    tf.TensorSpec(shape=(None, None, 3), dtype=tf.float32),\n","    tf.TensorSpec(shape=(None,), dtype=tf.int64)\n",")\n","train_set = tf.data.Dataset.from_generator(\n","    lambda: image_generator(train_filepaths),\n","    output_signature=output_signature\n",")\n","valid_set = tf.data.Dataset.from_generator(\n","    lambda: image_generator(eval_filepaths[:5]),\n","    output_signature=output_signature\n",")\n","test_set = tf.data.Dataset.from_generator(\n","    lambda: image_generator(eval_filepaths[5:]),\n","    output_signature=output_signature\n",")"],"metadata":{"id":"NlQfKZDxLabZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["with open(path / \"eval.tfrecord.classes\") as test_classes_file:\n","    test_classes = test_classes_file.readlines()\n","\n","with open(path / \"training.tfrecord.classes\") as train_classes_file:\n","    train_classes = train_classes_file.readlines()\n","\n","assert train_classes == test_classes\n","class_names = [name.strip().lower() for name in train_classes]"],"metadata":{"id":"-lZ77Gq3AQFZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["filepath = time.strftime(f\"{drive_path}/models/sketchrnn_%Y_%m_%d-%H_%M_%S\")\n","checkpoint_cb = keras.callbacks.ModelCheckpoint(\n","    filepath,\n","    monitor='val_loss',\n","    verbose=0,\n","    save_best_only=True,\n","    save_weights_only=False,\n","    mode='auto',\n","    save_freq='epoch',\n","    initial_value_threshold=None\n",")\n","\n","\n","model = keras.models.Sequential([\n","    keras.layers.Conv1D(32, kernel_size=5, strides=2, activation=\"relu\"),\n","    keras.layers.BatchNormalization(),\n","    keras.layers.Conv1D(64, kernel_size=5, strides=2, activation=\"relu\"),\n","    keras.layers.BatchNormalization(),\n","    keras.layers.Conv1D(128, kernel_size=3, strides=2, activation=\"relu\"),\n","    keras.layers.BatchNormalization(),\n","    keras.layers.LSTM(128, return_sequences=True),\n","    keras.layers.LSTM(128),\n","    keras.layers.Dense(len(class_names), activation=\"softmax\")\n","])\n","optimizer = keras.optimizers.SGD(learning_rate=1e-2, clipnorm=1.)\n","model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer,\n","              metrics=[\"accuracy\"])"],"metadata":{"id":"FhZ884ilHnjQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 3,450,000 training size\n","model.fit(train_set, epochs=2, validation_data=valid_set,\n","          callbacks=[checkpoint_cb])"],"metadata":{"id":"cVi9HOdkLASq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 10."],"metadata":{"id":"FWxKKiDHHE4A"}},{"cell_type":"code","source":["DOWNLOAD_ROOT = \"https://github.com/ageron/handson-ml2/raw/master/datasets/jsb_chorales/\"\n","FILENAME = \"jsb_chorales.tgz\"\n","filepath = keras.utils.get_file(FILENAME, DOWNLOAD_ROOT + FILENAME, extract=True)\n","path = Path(filepath).parent"],"metadata":{"id":"oC_KCIJIHGQv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_filepaths = sorted([str(record_path) for record_path in path.glob(\"train/chorale_*.csv\")])\n","valid_filepaths = sorted([str(record_path) for record_path in path.glob(\"valid/chorale_*.csv\")])\n","test_filepaths = sorted([str(record_path) for record_path in path.glob(\"test/chorale_*.csv\")])"],"metadata":{"id":"bPT-Y32YHjjk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","\n","\n","def create_chorales(filepaths):\n","    return [pd.read_csv(filepath).values.tolist() for filepath in filepaths]\n","\n","\n","train_chorales = create_chorales(train_filepaths)\n","valid_chorales = create_chorales(valid_filepaths)\n","test_chorales = create_chorales(test_filepaths)"],"metadata":{"id":"jy2rEbzobeYW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["notes = set()\n","for chorales in (train_chorales, valid_chorales, test_chorales):\n","    for chorale in chorales:\n","        for chord in chorale:\n","            # |= is union operator\n","            notes |= set(chord)\n","\n","n_notes = len(notes)\n","min_note = min(notes - {0})\n","max_note = max(notes)\n","\n","assert min_note == 36\n","assert max_note == 81"],"metadata":{"id":"88RQzpG0RCa3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["'''\n","Creates dataset from chorales, then uses it to create a flattened sequences\n","of notes, where the last note is used as label. The notes are also normalized\n","to range 0-46\n","'''\n","def create_target(batch):\n","    X = batch[:, :-1]\n","    Y = batch[:, 1:] # predict next note in each arpegio, at each step\n","    return X, Y\n","\n","def preprocess(window):\n","    window = tf.where(window == 0, window, window - min_note + 1) # shift values\n","    return tf.reshape(window, [-1]) # convert to arpegio\n","\n","def bach_dataset(chorales, batch_size=32, shuffle_buffer_size=None,\n","                 window_size=32, window_shift=16, cache=True):\n","    def batch_window(window):\n","        return window.batch(window_size + 1)\n","\n","    def to_windows(chorale):\n","        dataset = tf.data.Dataset.from_tensor_slices(chorale)\n","        dataset = dataset.window(window_size + 1, window_shift, drop_remainder=True)\n","        return dataset.flat_map(batch_window)\n","\n","    chorales = tf.ragged.constant(chorales, ragged_rank=1)\n","    dataset = tf.data.Dataset.from_tensor_slices(chorales)\n","    dataset = dataset.flat_map(to_windows).map(preprocess)\n","    if cache:\n","        dataset = dataset.cache()\n","    if shuffle_buffer_size:\n","        dataset = dataset.shuffle(shuffle_buffer_size)\n","    dataset = dataset.batch(batch_size)\n","    dataset = dataset.map(create_target)\n","    return dataset.prefetch(1)\n"],"metadata":{"id":"ZQVh0w1MgD6d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_set = bach_dataset(train_chorales, shuffle_buffer_size=1000)\n","valid_set = bach_dataset(valid_chorales)\n","test_set = bach_dataset(test_chorales)"],"metadata":{"id":"YPm4b1LCmExC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["n_embedding_dims = 5\n","\n","model = keras.models.Sequential([\n","    keras.layers.Embedding(input_dim=n_notes, output_dim=n_embedding_dims,\n","                           input_shape=[None]),\n","    keras.layers.Conv1D(32, kernel_size=2, padding=\"causal\", activation=\"relu\"),\n","    keras.layers.BatchNormalization(),\n","    keras.layers.Conv1D(48, kernel_size=2, padding=\"causal\", activation=\"relu\", dilation_rate=2),\n","    keras.layers.BatchNormalization(),\n","    keras.layers.Conv1D(64, kernel_size=2, padding=\"causal\", activation=\"relu\", dilation_rate=4),\n","    keras.layers.BatchNormalization(),\n","    keras.layers.Conv1D(96, kernel_size=2, padding=\"causal\", activation=\"relu\", dilation_rate=8),\n","    keras.layers.BatchNormalization(),\n","    keras.layers.LSTM(256, return_sequences=True),\n","    keras.layers.Dense(n_notes, activation=\"softmax\")\n","])\n","\n","model.summary()"],"metadata":{"id":"Yhj6ynmfmS99"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["filepath = time.strftime(f\"{drive_path}/models/bach_%Y_%m_%d-%H_%M_%S\")\n","checkpoint_cb = keras.callbacks.ModelCheckpoint(\n","    filepath,\n","    monitor='val_loss',\n","    verbose=0,\n","    save_best_only=True,\n","    save_weights_only=False,\n","    mode='auto',\n","    save_freq='epoch',\n","    initial_value_threshold=None\n",")\n","\n","optimizer = keras.optimizers.Nadam(learning_rate=1e-3)\n","model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer,\n","              metrics=[\"accuracy\"])\n","model.fit(train_set, epochs=20, validation_data=valid_set,\n","          callbacks=[checkpoint_cb])"],"metadata":{"id":"IZ2mqIFZmVnn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.evaluate(test_set)"],"metadata":{"id":"JTKYNFfAmoH5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["'''\n","Predict returns probabilites of notes for each position in sequence.\n","Argmax then gives the index (note) with the highest probability for each\n","position in sequence. The last element in this new sequence is the new note.\n","'''\n","def generate_chorale(model, seed_chords, length):\n","    arpegio = preprocess(tf.constant(seed_chords, dtype=tf.int64))\n","    arpegio = tf.reshape(arpegio, [1, -1])\n","    for chord in range(length):\n","        for note in range(4):\n","            #next_note = model.predict_classes(arpegio)[:1, -1:]\n","            next_note = np.argmax(model.predict(arpegio), axis=-1)[:1, -1:]\n","            arpegio = tf.concat([arpegio, next_note], axis=1)\n","    arpegio = tf.where(arpegio == 0, arpegio, arpegio + min_note - 1)\n","    return tf.reshape(arpegio, shape=[-1, 4])\n","\n","'''\n","Predicts the probability of each note, scales each probability logarithmically,\n","then randomly selects index (note) from this probability distribution.\n","'''\n","def generate_chorale_v2(model, seed_chords, length, temperature=1):\n","    arpegio = preprocess(tf.constant(seed_chords, dtype=tf.int64))\n","    arpegio = tf.reshape(arpegio, [1, -1])\n","    for chord in range(length):\n","        for note in range(4):\n","            next_note_probas = model.predict(arpegio)[0, -1:]\n","            rescaled_logits = tf.math.log(next_note_probas) / temperature\n","            next_note = tf.random.categorical(rescaled_logits, num_samples=1)\n","            arpegio = tf.concat([arpegio, next_note], axis=1)\n","    arpegio = tf.where(arpegio == 0, arpegio, arpegio + min_note - 1)\n","    return tf.reshape(arpegio, shape=[-1, 4])"],"metadata":{"id":"WeQxwI1gm8jM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from IPython.display import Audio\n","\n","def notes_to_frequencies(notes):\n","    # Frequency doubles when you go up one octave; there are 12 semi-tones\n","    # per octave; Note A on octave 4 is 440 Hz, and it is note number 69.\n","    return 2 ** ((np.array(notes) - 69) / 12) * 440\n","\n","def frequencies_to_samples(frequencies, tempo, sample_rate):\n","    note_duration = 60 / tempo # the tempo is measured in beats per minutes\n","    # To reduce click sound at every beat, we round the frequencies to try to\n","    # get the samples close to zero at the end of each note.\n","    frequencies = np.round(note_duration * frequencies) / note_duration\n","    n_samples = int(note_duration * sample_rate)\n","    time = np.linspace(0, note_duration, n_samples)\n","    sine_waves = np.sin(2 * np.pi * frequencies.reshape(-1, 1) * time)\n","    # Removing all notes with frequencies ≤ 9 Hz (includes note 0 = silence)\n","    sine_waves *= (frequencies > 9.).reshape(-1, 1)\n","    return sine_waves.reshape(-1)\n","\n","def chords_to_samples(chords, tempo, sample_rate):\n","    freqs = notes_to_frequencies(chords)\n","    freqs = np.r_[freqs, freqs[-1:]] # make last note a bit longer\n","    merged = np.mean([frequencies_to_samples(melody, tempo, sample_rate)\n","                     for melody in freqs.T], axis=0)\n","    n_fade_out_samples = sample_rate * 60 // tempo # fade out last note\n","    fade_out = np.linspace(1., 0., n_fade_out_samples)**2\n","    merged[-n_fade_out_samples:] *= fade_out\n","    return merged\n","\n","def play_chords(chords, tempo=160, amplitude=0.1, sample_rate=44100, filepath=None):\n","    samples = amplitude * chords_to_samples(chords, tempo, sample_rate)\n","    if filepath:\n","        from scipy.io import wavfile\n","        samples = (2**15 * samples).astype(np.int16)\n","        wavfile.write(filepath, sample_rate, samples)\n","        return display(Audio(filepath))\n","    else:\n","        return display(Audio(samples, rate=sample_rate))"],"metadata":{"id":"J-Ww216Cnvbn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["seed_chords = test_chorales[2][:8]\n","play_chords(seed_chords, amplitude=0.2)"],"metadata":{"id":"w5Sl5GVWpDfd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["new_chorale = generate_chorale(model, seed_chords, 56)\n","play_chords(new_chorale)"],"metadata":{"id":"oOpx546Oo6sK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["new_chorale_v2_medium = generate_chorale_v2(model, seed_chords, 56, temperature=1.0)\n","play_chords(new_chorale_v2_medium, filepath=\"bach_medium.wav\")"],"metadata":{"id":"xsdGIBi_o4yB"},"execution_count":null,"outputs":[]}]}