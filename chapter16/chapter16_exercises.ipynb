{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["Rq49bx5eYgaM"],"gpuType":"T4","authorship_tag":"ABX9TyNmJV6El1atNxKg5Wkuy/m3"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["!pip install tensorflow_addons"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"boNT7lHOPapp","executionInfo":{"status":"ok","timestamp":1719299596668,"user_tz":-120,"elapsed":6509,"user":{"displayName":"Tomas David","userId":"17081504748808486304"}},"outputId":"a46d1554-9af3-48f7-890f-01c636b77cdb"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting tensorflow_addons\n","  Downloading tensorflow_addons-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (611 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.8/611.8 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow_addons) (24.1)\n","Collecting typeguard<3.0.0,>=2.7 (from tensorflow_addons)\n","  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n","Installing collected packages: typeguard, tensorflow_addons\n","Successfully installed tensorflow_addons-0.23.0 typeguard-2.13.3\n"]}]},{"cell_type":"code","source":["import tensorflow as tf\n","import tensorflow.keras as keras\n","from tensorflow.keras import layers\n","import tensorflow_addons as tfa\n","import numpy as np\n","import secrets\n","import time\n","import datetime\n","import re"],"metadata":{"id":"LHKKQH8BdSeN","executionInfo":{"status":"ok","timestamp":1719299599339,"user_tz":-120,"elapsed":402,"user":{"displayName":"Tomas David","userId":"17081504748808486304"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"1a5b981a-98fd-42af-c4d8-9eb55a607316"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n","\n","TensorFlow Addons (TFA) has ended development and introduction of new features.\n","TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n","Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n","\n","For more information see: https://github.com/tensorflow/addons/issues/2807 \n","\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount(\"/content/gdrive\")\n","drive_path = \"gdrive/MyDrive/MachineLearning/HandsOnMachineLearning/chapter16\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"74NVqGwFf130","executionInfo":{"status":"ok","timestamp":1719299630920,"user_tz":-120,"elapsed":19491,"user":{"displayName":"Tomas David","userId":"17081504748808486304"}},"outputId":"a1cd33a8-1a7b-4b03-8202-08982e550106"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}]},{"cell_type":"markdown","source":["# 8."],"metadata":{"id":"Rq49bx5eYgaM"}},{"cell_type":"code","source":["class Node():\n","    def __init__(self, letter, next_nodes=None):\n","        self.letter = letter\n","        self.next_nodes = next_nodes\n","\n","    def pick_next_node(self):\n","        return secrets.choice(self.next_nodes)\n","\n","    def set_next_nodes(self, next_nodes):\n","        self.next_nodes = next_nodes\n","\n","\n","class ReberString():\n","    def __init__(self, postlayers):\n","        self.end = Node(\"E\")\n","        layer3_V = Node(\"V\")\n","        layer3_S = Node(\"S\")\n","        layer3_X = Node(\"X\")\n","        layer3_P = Node(\"P\")\n","        layer2_V = Node(\"V\")\n","        layer2_T = Node(\"T\")\n","        layer2_X = Node(\"X\")\n","        layer2_S = Node(\"S\")\n","        layer1_P = Node(\"P\")\n","        layer1_T = Node(\"T\")\n","        self.start = Node(\"B\")\n","\n","        self.end.set_next_nodes(postlayers)\n","        layer3_V.set_next_nodes([end])\n","        layer3_S.set_next_nodes([end])\n","        layer3_X.set_next_nodes([layer2_T, layer2_V])\n","        layer3_P.set_next_nodes([layer3_X, layer3_S])\n","\n","        layer2_V.set_next_nodes([layer3_P, layer3_V])\n","        layer2_T.set_next_nodes([layer2_T, layer2_V])\n","        layer2_X.set_next_nodes([layer3_X, layer3_S])\n","        layer2_S.set_next_nodes([layer2_S, layer2_X])\n","\n","        layer1_P.set_next_nodes([layer2_T, layer2_V])\n","        layer1_T.set_next_nodes([layer2_S, layer2_X])\n","        self.start.set_next_nodes([layer1_P, layer1_T])\n","\n","\n","end = Node(\"E\")\n","postlayer_P = Node(\"P\", [end])\n","postlayer_T = Node(\"T\", [end])\n","string_P = ReberString(postlayer_P)\n","string_T = ReberString(postlayer_T)\n","prelayer_P = Node(\"P\", [string_P.start])\n","prelayer_T = Node(\"T\", [string_T.start])\n","start = Node(\"B\", [prelayer_T, prelayer_P])\n","\n","unique_letters = [\"B\", \"E\", \"P\", \"S\", \"T\", \"V\", \"X\"]"],"metadata":{"id":"lSpI3ubKMj2n"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def generate_valid_sequence(start, join=True):\n","    letters = []\n","    cur_node = start\n","\n","    while cur_node.next_nodes is not None:\n","        letters.append(cur_node.letter)\n","        cur_node = cur_node.pick_next_node()\n","\n","    if join:\n","        valid_string = \"\".join(letters)\n","        return valid_string\n","    return letters\n","\n","\n","def one_hot_encoding(string, unique_letters):\n","    return [unique_letters.index(c) for c in string]\n","\n","\n","def create_valid_data(length, start, unique_letters):\n","    valid_strings = []\n","    for _ in range(length//2):\n","        valid_string = generate_valid_sequence(start)\n","        valid_strings.append(one_hot_encoding(valid_string, unique_letters))\n","    return valid_strings\n","\n","\n","def create_invalid_data(length, start, unique_letters, n_invalid_letters=1):\n","    invalid_strings = []\n","    for _ in range(length//2):\n","        letters = generate_valid_sequence(start, False)\n","        indices = secrets.SystemRandom().sample(range(len(letters)), n_invalid_letters)\n","        for i in indices:\n","            cur_letter = letters[i]\n","            new_letter = secrets.choice([letter for letter in unique_letters\n","                                        if letter != cur_letter])\n","            letters[i] = new_letter\n","        new_string = \"\".join(letters)\n","        invalid_strings.append(one_hot_encoding(new_string, unique_letters))\n","    return invalid_strings\n","\n","\n","\n","def create_dataset(length, start, unique_letters, training=False):\n","    valid_data = create_valid_data(length, start, unique_letters)\n","    invalid_data = create_invalid_data(length, start, unique_letters, 1)\n","    data = [*valid_data, *invalid_data]\n","    X = tf.ragged.constant(data, ragged_rank=1)\n","    y = np.array([[1.] for _ in range(len(valid_data))] +\n","                 [[0.] for _ in range(len(invalid_data))])\n","    return X, y\n","\n","\n","X_train, y_train = create_dataset(7500, start, unique_letters, True)\n","X_valid, y_valid = create_dataset(1500, start, unique_letters)\n","X_test, y_test = create_dataset(1000, start, unique_letters)"],"metadata":{"id":"SU2Y6spyXftc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["filepath = time.strftime(f\"{drive_path}/models/reberstring_%Y_%m_%d-%H_%M_%S\")\n","checkpoint_cb = keras.callbacks.ModelCheckpoint(\n","    filepath,\n","    monitor='val_loss',\n","    verbose=0,\n","    save_best_only=True,\n","    save_weights_only=False,\n","    mode='auto',\n","    save_freq='epoch',\n","    initial_value_threshold=None\n",")\n","embedding_size = 5\n","\n","model = keras.models.Sequential([\n","    layers.InputLayer(input_shape=[None], dtype=tf.int32, ragged=True),\n","    layers.Embedding(input_dim=len(unique_letters), output_dim=embedding_size),\n","    layers.GRU(30),\n","    layers.Dense(1, activation=\"sigmoid\")\n","])\n","optimizer = keras.optimizers.SGD(learning_rate=0.02, momentum=0.95, nesterov=True)\n","model.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n","model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid),\n","          callbacks=[checkpoint_cb])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"8C5S8Klse5Wj","executionInfo":{"status":"ok","timestamp":1719227375941,"user_tz":-120,"elapsed":98548,"user":{"displayName":"Tomas David","userId":"17081504748808486304"}},"outputId":"5c82e7da-c55d-4b79-f04c-aa8bd29222e1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","235/235 [==============================] - 11s 37ms/step - loss: 0.6946 - accuracy: 0.4952 - val_loss: 0.6925 - val_accuracy: 0.5020\n","Epoch 2/20\n","235/235 [==============================] - 4s 16ms/step - loss: 0.6922 - accuracy: 0.5065 - val_loss: 0.6864 - val_accuracy: 0.4967\n","Epoch 3/20\n","235/235 [==============================] - 4s 16ms/step - loss: 0.6776 - accuracy: 0.5369 - val_loss: 0.6624 - val_accuracy: 0.4753\n","Epoch 4/20\n","235/235 [==============================] - 5s 20ms/step - loss: 0.6599 - accuracy: 0.5608 - val_loss: 0.6596 - val_accuracy: 0.5913\n","Epoch 5/20\n","235/235 [==============================] - 5s 19ms/step - loss: 0.6565 - accuracy: 0.5740 - val_loss: 0.6341 - val_accuracy: 0.6233\n","Epoch 6/20\n","235/235 [==============================] - 6s 25ms/step - loss: 0.6415 - accuracy: 0.6116 - val_loss: 0.6238 - val_accuracy: 0.6333\n","Epoch 7/20\n","235/235 [==============================] - 4s 17ms/step - loss: 0.5881 - accuracy: 0.6915 - val_loss: 0.4941 - val_accuracy: 0.7987\n","Epoch 8/20\n","235/235 [==============================] - 4s 18ms/step - loss: 0.4366 - accuracy: 0.8144 - val_loss: 0.4416 - val_accuracy: 0.8193\n","Epoch 9/20\n","235/235 [==============================] - 5s 21ms/step - loss: 0.3621 - accuracy: 0.8504 - val_loss: 0.3113 - val_accuracy: 0.8773\n","Epoch 10/20\n","235/235 [==============================] - 4s 16ms/step - loss: 0.2268 - accuracy: 0.9203 - val_loss: 0.2186 - val_accuracy: 0.9140\n","Epoch 11/20\n","235/235 [==============================] - 4s 16ms/step - loss: 0.1144 - accuracy: 0.9697 - val_loss: 0.1000 - val_accuracy: 0.9753\n","Epoch 12/20\n","235/235 [==============================] - 2s 10ms/step - loss: 0.0801 - accuracy: 0.9807 - val_loss: 0.1129 - val_accuracy: 0.9833\n","Epoch 13/20\n","235/235 [==============================] - 4s 19ms/step - loss: 0.0626 - accuracy: 0.9872 - val_loss: 0.0810 - val_accuracy: 0.9807\n","Epoch 14/20\n","235/235 [==============================] - 2s 7ms/step - loss: 0.0569 - accuracy: 0.9877 - val_loss: 0.0818 - val_accuracy: 0.9840\n","Epoch 15/20\n","235/235 [==============================] - 4s 18ms/step - loss: 0.0582 - accuracy: 0.9884 - val_loss: 0.0743 - val_accuracy: 0.9847\n","Epoch 16/20\n","235/235 [==============================] - 3s 11ms/step - loss: 0.0522 - accuracy: 0.9901 - val_loss: 0.0752 - val_accuracy: 0.9847\n","Epoch 17/20\n","235/235 [==============================] - 4s 16ms/step - loss: 0.0503 - accuracy: 0.9901 - val_loss: 0.0701 - val_accuracy: 0.9860\n","Epoch 18/20\n","235/235 [==============================] - 5s 19ms/step - loss: 0.0483 - accuracy: 0.9900 - val_loss: 0.0700 - val_accuracy: 0.9860\n","Epoch 19/20\n","235/235 [==============================] - 5s 21ms/step - loss: 0.0489 - accuracy: 0.9903 - val_loss: 0.0667 - val_accuracy: 0.9860\n","Epoch 20/20\n","235/235 [==============================] - 2s 7ms/step - loss: 0.0493 - accuracy: 0.9901 - val_loss: 0.0673 - val_accuracy: 0.9860\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.History at 0x78700f0a76a0>"]},"metadata":{},"execution_count":6}]},{"cell_type":"markdown","source":["# 9."],"metadata":{"id":"2W4vPxGk7tPg"}},{"cell_type":"code","source":["YEARS = list(range(1990, 2031))\n","MONTHS = list(range(1, 13))\n","DAYS = list(range(1, 32))\n","\n","\n","\n","def create_dates(length):\n","    contexts = []\n","    targets = []\n","\n","    i = 0\n","    while i < length:\n","        try:\n","            year = secrets.choice(YEARS)\n","            month = secrets.choice(MONTHS)\n","            day = secrets.choice(DAYS)\n","            date = datetime.datetime(year, month, day)\n","            context = date.strftime(\"%B %d, %Y\").replace(' 0', ' ')\n","            target = date.strftime(\"%Y-%m-%d\")\n","            contexts.append(context)\n","            targets.append(target)\n","            i += 1\n","        except ValueError:\n","            continue\n","\n","    return contexts, targets"],"metadata":{"id":"998f3fnvLyth","executionInfo":{"status":"ok","timestamp":1719299630920,"user_tz":-120,"elapsed":4,"user":{"displayName":"Tomas David","userId":"17081504748808486304"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["def standardize(input_data):\n","    lowercase = tf.strings.lower(input_data)\n","    stripped_html = tf.strings.regex_replace(lowercase, '<br />', ' ')\n","    stripped_punctuation = tf.strings.regex_replace(stripped_html, '[%s]' % re.escape('!\"#$%&()*+,./:;<=>?@[\\\\]^_`{|}~'), '')\n","    seperate_dash = tf.strings.regex_replace(stripped_punctuation, \"-\", \" - \")\n","    return seperate_dash\n","\n","\n","MONTHS_TEXT = [\n","    \"January\", \"February\", \"March\", \"April\", \"May\", \"June\",\n","    \"July\", \"August\", \"September\", \"October\", \"November\", \"December\"\n","]\n","DAYS_WITH_ZERO = [\"01\", \"02\", \"03\", \"04\", \"05\", \"06\", \"07\", \"08\", \"09\"]\n","\n","vocab_size = 100\n","embed_size = 5\n","\n","encoder_vectorize_layer = layers.TextVectorization(\n","    max_tokens=vocab_size,\n","    output_mode=\"int\",\n","    output_sequence_length=embed_size\n",")\n","encoder_vectorize_layer.adapt([\n","    *MONTHS_TEXT, *map(str, DAYS), *map(str, YEARS)\n","])\n","\n","decoder_vectorize_layer = layers.TextVectorization(\n","    max_tokens=vocab_size,\n","    standardize=standardize,\n","    output_mode=\"int\",\n","    output_sequence_length=embed_size\n",")\n","decoder_vectorize_layer.adapt([\n","    *map(str, list(range(10, 32))), *map(str, YEARS), \"-\", *DAYS_WITH_ZERO\n","])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8RUqAHHLciPz","executionInfo":{"status":"ok","timestamp":1719299878544,"user_tz":-120,"elapsed":358,"user":{"displayName":"Tomas David","userId":"17081504748808486304"}},"outputId":"5e45dd71-4ca1-498f-fa24-d0613a34e5fb"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:5 out of the last 13 calls to <function PreprocessingLayer.make_adapt_function.<locals>.adapt_step at 0x7e992c14b9a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","WARNING:tensorflow:5 out of the last 13 calls to <function PreprocessingLayer.make_adapt_function.<locals>.adapt_step at 0x7e98e214d630> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"]}]},{"cell_type":"code","source":["print(encoder_vectorize_layer(\"April 22, 2019\"))\n","print(decoder_vectorize_layer(\"2019-22-04\"))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CJgRMDEQ-6Mj","executionInfo":{"status":"ok","timestamp":1719299882981,"user_tz":-120,"elapsed":347,"user":{"displayName":"Tomas David","userId":"17081504748808486304"}},"outputId":"1b5e715d-4a12-46d1-fb82-9028d9bfa8d4"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["tf.Tensor([13 30 43  0  0], shape=(5,), dtype=int64)\n","tf.Tensor([24 74 11 74 70], shape=(5,), dtype=int64)\n"]}]},{"cell_type":"code","source":["X_train, y_train = create_dates(7500)\n","X_valid, y_valid = create_dates(1500)\n","X_test, y_test = create_dates(1000)"],"metadata":{"id":"hYnCxhnOhS_E","executionInfo":{"status":"ok","timestamp":1719299888512,"user_tz":-120,"elapsed":660,"user":{"displayName":"Tomas David","userId":"17081504748808486304"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["X_train = encoder_vectorize_layer(X_train)\n","y_train = decoder_vectorize_layer(y_train)\n","X_valid = encoder_vectorize_layer(X_valid)\n","y_valid = decoder_vectorize_layer(y_valid)\n","X_test = encoder_vectorize_layer(X_test)\n","#y_test = decoder_vectorize_layer(y_test)"],"metadata":{"id":"wSenvil5POij","executionInfo":{"status":"ok","timestamp":1719299890346,"user_tz":-120,"elapsed":6,"user":{"displayName":"Tomas David","userId":"17081504748808486304"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["encoder_inputs = layers.Input(shape=[None], dtype=np.int32)\n","decoder_inputs = layers.Input(shape=[None], dtype=np.int32)\n","sequence_lengths = layers.Input(shape=[], dtype=np.int32)\n","\n","embeddings = keras.layers.Embedding(vocab_size, embed_size)\n","encoder_embeddings = embeddings(encoder_inputs)\n","decoder_embeddings = embeddings(decoder_inputs)\n","\n","encoder = layers.LSTM(512, return_state=True)\n","encoder_outputs, state_h, state_c = encoder(encoder_embeddings)\n","encoder_state = [state_h, state_c]\n","\n","sampler = tfa.seq2seq.sampler.TrainingSampler()\n","decoder_cell = layers.LSTMCell(512)\n","output_layer = layers.Dense(vocab_size)\n","\n","decoder = tfa.seq2seq.basic_decoder.BasicDecoder(decoder_cell, sampler,\n","                                                 output_layer=output_layer)\n","final_outputs, final_state, final_sequence_lengths = decoder(\n","    decoder_embeddings, initial_state=encoder_state,\n","    sequence_length=sequence_lengths\n",")\n","Y_proba = tf.nn.softmax(final_outputs.rnn_output)\n","model = keras.Model(inputs=[encoder_inputs, decoder_inputs, sequence_lengths],\n","                    outputs=[Y_proba])\n","model.compile(optimizer=\"rmsprop\", loss=\"sparse_categorical_crossentropy\",\n","              metrics=[\"accuracy\"])"],"metadata":{"id":"OUUFo22b7umv","executionInfo":{"status":"ok","timestamp":1719299894589,"user_tz":-120,"elapsed":1022,"user":{"displayName":"Tomas David","userId":"17081504748808486304"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["sequence_lengths = np.array([len(seq) for seq in X_train])\n","model.fit([X_train, y_train, sequence_lengths], y_train, epochs=15, validation_data=(X_valid, y_valid))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"aWczuTnlMp_v","executionInfo":{"status":"ok","timestamp":1719299984708,"user_tz":-120,"elapsed":88354,"user":{"displayName":"Tomas David","userId":"17081504748808486304"}},"outputId":"2d4f48cb-6653-438e-b6cd-c52f3073be49"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/15\n","235/235 [==============================] - 9s 22ms/step - loss: 2.3612\n","Epoch 2/15\n","235/235 [==============================] - 4s 18ms/step - loss: 1.8259\n","Epoch 3/15\n","235/235 [==============================] - 6s 23ms/step - loss: 1.6059\n","Epoch 4/15\n","235/235 [==============================] - 4s 16ms/step - loss: 1.3458\n","Epoch 5/15\n","235/235 [==============================] - 4s 16ms/step - loss: 0.9556\n","Epoch 6/15\n","235/235 [==============================] - 6s 24ms/step - loss: 0.5455\n","Epoch 7/15\n","235/235 [==============================] - 5s 20ms/step - loss: 0.2243\n","Epoch 8/15\n","235/235 [==============================] - 4s 16ms/step - loss: 0.0819\n","Epoch 9/15\n","235/235 [==============================] - 5s 23ms/step - loss: 0.0241\n","Epoch 10/15\n","235/235 [==============================] - 4s 16ms/step - loss: 0.0052\n","Epoch 11/15\n","235/235 [==============================] - 4s 16ms/step - loss: 0.0021\n","Epoch 12/15\n","235/235 [==============================] - 6s 25ms/step - loss: 0.0013\n","Epoch 13/15\n","235/235 [==============================] - 6s 26ms/step - loss: 9.3334e-04\n","Epoch 14/15\n","235/235 [==============================] - 4s 16ms/step - loss: 7.3166e-04\n","Epoch 15/15\n","235/235 [==============================] - 6s 23ms/step - loss: 6.0121e-04\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.History at 0x7e992c6ec340>"]},"metadata":{},"execution_count":23}]},{"cell_type":"code","source":["inference_sampler = tfa.seq2seq.sampler.GreedyEmbeddingSampler(\n","    embedding_fn=embeddings)\n","inference_decoder = tfa.seq2seq.basic_decoder.BasicDecoder(\n","    decoder_cell, inference_sampler, output_layer=output_layer,\n","    maximum_iterations=embed_size)\n","batch_size = tf.shape(encoder_inputs)[:1]\n","start_tokens = tf.fill(dims=batch_size, value=101)\n","final_outputs, final_state, final_sequence_lengths = inference_decoder(\n","    start_tokens,\n","    initial_state=encoder_state,\n","    start_tokens=start_tokens,\n","    end_token=0\n",")\n","\n","inference_model = keras.models.Model(inputs=[encoder_inputs],\n","                                     outputs=[final_outputs.sample_id])"],"metadata":{"id":"MeNF1XtWVbUr","executionInfo":{"status":"ok","timestamp":1719302161311,"user_tz":-120,"elapsed":46086,"user":{"displayName":"Tomas David","userId":"17081504748808486304"}}},"execution_count":33,"outputs":[]},{"cell_type":"code","source":["predictions = inference_model.predict(X_test)[0]\n","vocab = decoder_vectorize_layer.get_vocabulary()\n","print(\" \".join([vocab[int(each)] for each in tf.squeeze(predictions)]))\n","print(y_test[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LTfp1JqNZtFY","executionInfo":{"status":"ok","timestamp":1719302316562,"user_tz":-120,"elapsed":2,"user":{"displayName":"Tomas David","userId":"17081504748808486304"}},"outputId":"334abd59-6457-49f0-9e3a-8717efd0938e"},"execution_count":39,"outputs":[{"output_type":"stream","name":"stdout","text":["2014 - - - 09\n","2014-02-08\n"]}]}]}